{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481c8c5-d3ba-418a-8cb8-293ef4c0523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo a Passo para o Bagging\n",
    "\n",
    "#1. Preparar o Dataset\n",
    "#Antes de aplicar o Bagging:\n",
    "\n",
    "#Faça o pré-processamento dos dados (tratamento de nulos, codificação, normalização se necessário).\n",
    "\n",
    "#Divida o dataset em features (X) e target (y).\n",
    "\n",
    "#2. Gerar Amostras Bootstrap\n",
    "#Crie várias amostras aleatórias com reposição a partir do conjunto de treino.\n",
    "\n",
    "#Cada amostra pode ter o mesmo tamanho do dataset original ou menor.\n",
    "\n",
    "#Exemplo: se você quiser criar 10 modelos, gere 10 subconjuntos bootstrap.\n",
    "\n",
    "# Como é com reposição, algumas observações podem aparecer mais de uma vez e outras podem não aparecer.\n",
    "\n",
    "#3. Treinar Modelos Independentes\n",
    "#Para cada subconjunto bootstrap, treine um modelo fraco (base learner).\n",
    "\n",
    "#Normalmente se usa árvore de decisão sem poda, mas pode ser outro algoritmo.\n",
    "\n",
    "# Os modelos são treinados em paralelo e de forma independente.\n",
    "\n",
    "#4. Fazer Previsões (Agregação)\n",
    "#Para novas instâncias, cada modelo faz sua previsão.\n",
    "\n",
    "#Agregue os resultados das seguintes formas:\n",
    "\n",
    "#Classificação: voto da maioria.\n",
    "\n",
    "#Regressão: média das previsões.\n",
    "\n",
    "#5. Avaliar o Modelo Final\n",
    "#Compare a performance do modelo ensemble com o modelo individual (sem bagging).\n",
    "\n",
    "#Utilize métricas adequadas:\n",
    "\n",
    "#Classificação: accuracy, precision, recall, f1.\n",
    "\n",
    "#Regressão: RMSE, MAE, R².\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7253014-22b1-4d87-b368-acae01b82372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagine que você tá com um conjunto de dados e quer treinar um modelo pra prever algo, se uma pessoa vai comprar ou não um produto. Só que, se você treina uma única árvore de decisão, ela pode ficar muito influenciada por alguns dados específicos.\n",
    "\n",
    "#O que o Bagging faz é o seguinte:\n",
    "\n",
    "#Ele pega teu conjunto de dados e cria várias amostras aleatórias com repetição (tipo: sorteia várias vezes com reposição).\n",
    "\n",
    "#Em cada uma dessas amostras, ele treina um modelo separado — normalmente, usa árvores de decisão.\n",
    "\n",
    "#Depois, junta a resposta de todos esses modelos pra dar o resultado final.\n",
    "\n",
    "#Se for classificação, ele vê qual resposta apareceu mais entre os modelos (tipo votação).\n",
    "\n",
    "#Se for regressão, ele faz a média das respostas.\n",
    "\n",
    "#A vantagem é que isso ajuda a reduzir o overfitting e melhora a estabilidade do modelo. Você não fica mais dependente de uma única árvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342c3f83-9061-4b99-9676-00352f299ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Bagging: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "n_estimators = 10  \n",
    "modelos = []      \n",
    "\n",
    "for i in range(n_estimators):\n",
    "    indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_bootstrap = X_train[indices]\n",
    "    y_bootstrap = y_train[indices]\n",
    "    \n",
    "    modelo = DecisionTreeClassifier()\n",
    "    modelo.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "    modelos.append(modelo)\n",
    "\n",
    "def bagging_predict(X):\n",
    "    preds = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        preds.append(modelo.predict(X))  \n",
    "    \n",
    "    preds = np.array(preds).T\n",
    "    \n",
    "    final_preds = [Counter(amostra).most_common(1)[0][0] for amostra in preds]\n",
    "    return np.array(final_preds)\n",
    "\n",
    "y_pred = bagging_predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do Bagging: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b2991e-c5b1-4f39-9c26-1904461d6429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
